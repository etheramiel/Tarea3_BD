{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca4f66b-55ff-4f9f-87c9-0e2fa416bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb52b52-1b1a-477e-a65b-990fdfefc295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuraci√≥n ===\n",
    "# json_file_path = \"arxiv-metadata-oai-snapshot.json\"\n",
    "archivos = [f\"arxiv-part-{i:02d}.json\" for i in range(11)]\n",
    "batch_size = 200\n",
    "documentos_totales = 0\n",
    "# max_workers = 4  # Ajusta seg√∫n tu CPU y MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6932e2-13f1-4607-b127-11aa8c5e03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Conectar a MongoDB ===\n",
    "client = MongoClient(\"mongodb://mongo1:30001,mongo2:30002,mongo3:30003/?replicaSet=my-replica-set&readPreference=primary&appname=MongoDB%20Compass&ssl=false\")\n",
    "db = client[\"arxiv_db\"]\n",
    "collection = db[\"articles\"]\n",
    "# Crear √≠ndices para mejorar el rendimiento\n",
    "collection.create_index(\"id\")\n",
    "collection.create_index(\"categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2cf907-082f-4580-8ad7-625bc313cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Funci√≥n para insertar lote ===\n",
    "def insert_batch(batch):\n",
    "    try:\n",
    "        collection.insert_many(batch, ordered=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error al insertar batch:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4fbf1b3-952b-4ccd-bee1-5928d340335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Contar l√≠neas para tqdm ===\n",
    "# def count_lines(filepath):\n",
    "#     with open(filepath, 'r', encoding='utf-8') as f:\n",
    "#         return sum(1 for _ in f)\n",
    "\n",
    "# total_lines = count_lines(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85753b3-faf8-4f40-bc2a-cdd6134cd019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Cargando arxiv-part-00.json...\n",
      "  üîπ 10000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 20000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 30000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 40000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 50000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 60000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 70000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 80000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 90000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 100000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 110000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 120000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 130000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 140000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 150000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 160000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 170000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 180000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 190000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 200000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 210000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 220000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 230000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 240000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 250000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 260000 documentos procesados en arxiv-part-00.json...\n",
      "  üîπ 270000 documentos procesados en arxiv-part-00.json...\n",
      "‚úÖ Archivo arxiv-part-00.json cargado con 275492 documentos.\n",
      "\n",
      "üìÇ Cargando arxiv-part-01.json...\n",
      "  üîπ 10000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 20000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 30000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 40000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 50000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 60000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 70000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 80000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 90000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 100000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 110000 documentos procesados en arxiv-part-01.json...\n",
      "  üîπ 120000 documentos procesados en arxiv-part-01.json...\n"
     ]
    }
   ],
   "source": [
    "# === Lectura + carga paralela ===\n",
    "\n",
    "\n",
    "# for archivo in archivos:\n",
    "#     print(f\"\\nüìÇ Cargando {archivo}...\")\n",
    "#     # Contar l√≠neas para tqdm\n",
    "#     total_lines = sum(1 for _ in open(archivo, 'r', encoding='utf-8'))\n",
    "\n",
    "#     with open(archivo, 'r', encoding='utf-8') as f, tqdm(total=total_lines, desc=f\"Cargando {archivo}\") as pbar:\n",
    "#         batch = []\n",
    "#         for line in f:\n",
    "#             try:\n",
    "#                 record = json.loads(line)\n",
    "#                 record[\"pdf_source\"] = f\"https://arxiv.org/pdf/{record['id']}\"\n",
    "#                 batch.append(record)\n",
    "#                 if len(batch) >= batch_size:\n",
    "#                     insert_batch(batch)\n",
    "#                     batch = []\n",
    "#             except json.JSONDecodeError:\n",
    "#                 continue\n",
    "#             pbar.update(1)\n",
    "#         if batch:\n",
    "#             insert_batch(batch)\n",
    "\n",
    "# print(\"üéâ Todos los archivos fueron cargados.\")\n",
    "\n",
    "for archivo in archivos:\n",
    "    print(f\"\\nüìÇ Cargando {archivo}...\")\n",
    "    doc_count = 0\n",
    "    \n",
    "    # Usar with para manejo autom√°tico de archivos\n",
    "    with open(archivo, 'r', encoding='utf-8') as f:\n",
    "        # Usar tqdm para barra de progreso\n",
    "        for line in tqdm(f, desc=f\"Procesando {archivo}\"):\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                # Solo agregar pdf_source si no existe\n",
    "                if 'pdf_source' not in record:\n",
    "                    record[\"pdf_source\"] = f\"https://arxiv.org/pdf/{record['id']}\"\n",
    "                \n",
    "                # Insertar documentos de uno en uno para batches peque√±os\n",
    "                try:\n",
    "                    collection.insert_one(record)\n",
    "                    doc_count += 1\n",
    "                    documentos_totales += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error insertando documento: {str(e)[:200]}\")\n",
    "                    continue\n",
    "                \n",
    "                # Liberar memoria\n",
    "                del record\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decodificando JSON: {str(e)[:200]}\")\n",
    "                continue\n",
    "            \n",
    "            # Mostrar progreso cada 10,000 documentos\n",
    "            if doc_count % 10000 == 0:\n",
    "                print(f\"  üîπ {doc_count} documentos procesados en {archivo}...\")\n",
    "                client.admin.command('ping')  # Mantener la conexi√≥n viva\n",
    "\n",
    "    print(f\"‚úÖ Archivo {archivo} cargado con {doc_count} documentos.\")\n",
    "\n",
    "print(f\"\\nüéâ Todos los archivos cargados. Total insertados: {documentos_totales}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd426c95-495f-4859-b0d1-d6603c19d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Todos los documentos eliminados.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27018/\")\n",
    "db = client[\"arxiv_db\"]\n",
    "collection = db[\"articles\"]\n",
    "\n",
    "# ‚ö†Ô∏è Eliminar todos los documentos\n",
    "collection.delete_many({})\n",
    "print(\"üóëÔ∏è Todos los documentos eliminados.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d42b4-cefd-439d-9526-3400ef5bc645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
